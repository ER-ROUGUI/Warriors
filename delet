this is the publisher that is workig good in another divice 


import rclpy 
from rclpy.node import Node 
from sensor_msgs.msg import Image 
from geometry_msgs.msg import PointStamped
from cv_bridge import CvBridge 
import cv2 
import pyrealsense2 as rs
import numpy as np
 
class ImagePublisher(Node):
 
  def __init__(self):
 
  
    super().__init__('image_publisher')

    self.publisher_ = self.create_publisher(Image, '/camera/image_raw/compressed', 10) 
    self.bridge = CvBridge()
    self.center_sub = self.create_subscription(PointStamped , '/image/center_coordinates' , self.center_callback ,10)
    self.depth_pub = self.create_publisher(PointStamped , '/image/zDepth' , 10)

    self.pipeline =  rs.pipeline()
    config = rs.config()
    config.enable_stream(rs.stream.depth , 640 ,480 , rs.format.z16 , 30)
    config.enable_stream(rs.stream.color , 640 ,480 , rs.format.bgr8 , 30) # FPS = 30 

    self.pipeline.start(config)

  
    self.timer_period = 0.1  
    self.timer = self.create_timer(self.timer_period , self.timer_callback)
    self.x_center = None
    self.y_center = None 

  def timer_callback(self):
    frames = self.pipeline.wait_for_frames()  
    depth_frame = frames.get_depth_frame()
    color_frame = frames.get_color_frame()
    depth_frame = frames.get_depth_frame()
    if color_frame:
      color_image = np.asanyarray(color_frame.get_data()) 
      #rgb_image = cv2.cvtColor(color_image , cv2.COLOR_BGR2RGB)
 
    
#      if self.center_sub:
#          if self.center_x is not None and self.center_y is not None:
#            print(f"Center Coordinates : ({self.center_x} , {self.center_y})")
   
      _ , compressed_image_data = cv2.imencode('.jpg' , color_image , [cv2.IMWRITE_JPEG_QUALITY , 20])
      compressed_image_data  = compressed_image_data.tobytes()
      
      msg = Image()
      msg.header.stamp = self.get_clock().now().to_msg()

      msg.data = compressed_image_data 
      msg.encoding = 'jpeg'

      self.publisher_ .publish(msg) 
#      self.timer_callback(self.x_center , self.y_center)
    if self.x_center is not None and self.y_center is not None:
      zDepth = depth_frame.get_distance(int(self.x_center),int(self.y_center))
      depth_msg = PointStamped()
      depth_msg.header.stamp = self.get_clock().now().to_msg()
      depth_msg.point.x = self.x_center
      depth_msg.point.y = self.y_center
      depth_msg.point.z = zDepth
      self.depth_pub.publish(depth_msg)
      self.get_logger().info(f"Depth is  : {zDepth}")
  
  def center_callback(self ,msg):
#                  
    self.x_center = msg.point.x
    self.y_center = msg.point.y
#    zDepth = depth_frame.get_distance(int(self.x_center),int(self.y_center))
#    self.center_callback(self.x_center ,self.y_center)
#    self.get_logger().info(f"Depth is  : {zDepth})")
#    self.get_logger().info('I heard: "%s"' % msg.zDepth)
   
def main(args=None):

  rclpy.init(args=args)
  

  image_publisher = ImagePublisher()

  rclpy.spin(image_publisher)
  
  rclpy.shutdown()
  
if __name__ == '__main__':
  main()


and this is the subscriber to this  



import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from geometry_msgs.msg import PointStamped
import cv2
import numpy as np
from cv_bridge import CvBridge
from ultralytics import YOLO
import open3d as o3d 
from ament_index_python.packages import get_package_share_directory
import pyrealsense2 as rs
import os


# smart_robots_dir = get_package_share_directory("smart_robots_controller")
# model_file = os.path.join(smart_robots_dir, "config", "yolov8n.pt")
model_file = "/app/augmented-robots/server/nux_ws/src/smart_robots_controller/config/yolov8n.pt"

model = YOLO(model_file)
class ImageSubscriber(Node):

    def __init__(self):
        super().__init__('image_subscriber_yolo')
        self.image_sub = self.create_subscription(Image, '/camera/image_raw/compressed', self.image_callback, 10)
        self.depth_sub = self.create_subscription(PointStamped, 'image/zDepth', self.zDepth_callback, 10)

        self.bridge = CvBridge()

        timer_period = 0.5

        self.center_pub = self.create_publisher(PointStamped , '/image/center_coordinates' , 10)
        self.timer = self.create_timer(timer_period, self.timer_callback)
        self.i = 0
        self.center_coordinates = []


    

    def image_callback(self, msg):
        # global center_coordinates


        decoded_data = np.frombuffer(msg.data, dtype=np.uint8)
        decoded_image = cv2.imdecode(decoded_data, cv2.IMREAD_COLOR) 

        rbg_image = cv2.cvtColor(decoded_image , cv2.COLOR_BGR2RGB)

        results = model(rbg_image)
        results = model.predict(source=rbg_image, show=False, stream=True, verbose=False) 

        for r in results:
            boxes = r.boxes
            for box in boxes:
            # bounding box
                #print(box.xyxy[0])
                x1, y1, x2, y2 = box.xyxy[0]
                confidence =box.conf[0]
                cls = int(box.cls[0])

                if model.names[cls] == "person" and confidence > 0.5 : # we can use door or window instead person !!!
                    
                    cv2.rectangle(decoded_image , (int(x1),int(y1)) , (int(x2) , int(y2)) , (0,255,0) , 2)


                    (x_center,y_center) = (x2 + x1)/2, (y2+y1)/2 
                    center_coordinates = (int(x_center),int(y_center))

                    try:
                        
                        # zDepth = None  #depth_frame.get_distance(int(x_center),int(y_center))
                        print("Nothing just  ....." )

                    except (AttributeError , NameError):
                        print("Depth unavailable")

                    
                    # print(zDepth)

                    frame_center = (rbg_image.shape[1]//2 ,rbg_image.shape[0]//2)
                    error_x = center_coordinates[0] - frame_center[0]
                    error_y = center_coordinates[1] - frame_center[1]

                    self.center_coordinates.append(  (int(x_center) , int(y_center) ))

                    # print(f"Error: x ={error_x} , y={error_y}")

                    # center_msg = PointStamped()
                    # center_msg.header.stamp = self.get_clock().now().to_msg()
                    # center_msg.point.x = x_center
                    # center_msg.point.y = y_center
                    # self.center_pub.publish(center_msg)
                    # self.get_logger().info(f"Center coordinates : ({x_center} , {y_center})")
                    
                    if center_coordinates is not None :
            
                        cv2.circle(decoded_image, center_coordinates, 5, (0,0,255), 5)
                
               

        cv2.imshow('RealSense Image subscriber', decoded_image)
        cv2.waitKey(1)

    def timer_callback(self):


        if len(self.center_coordinates)>0 :

            x_center , y_center = self.center_coordinates[-1]

            msg = PointStamped()
            msg.header.stamp = self. get_clock().now().to_msg()
            msg.point.x = float(x_center)
            msg.point.y = float(y_center)

            self.center_pub.publish(msg)
            self.get_logger().info(f"Publishing center Coordinates: {msg.point.x} ,{msg.point.y}")
            self.i += 1
        else:
            self.get_logger().info('No center Coordinates:')

    def zDepth_callback(self ,msg):

        msg = PointStamped()
        msg.header.stamp = self.get_clock().now().to_msg()
        # msg.point.z = float(x_center)
        # x_center  =center_msg.point.x
        # y_center =center_msg.point.y
        zDepth  = msg.point.z

        self.get_logger().info(f"Publishing zDepth value: {zDepth}")
        

 



def main():
    rclpy.init()
    node = ImageSubscriber()
    rclpy.spin(node)
    rclpy.shutdown()

if __name__ == '__main__':
    main()

in raspberry pi i launch the file frome realsense camera rs_launch.py 
and i subscribe to /camera/image_raw with this 



import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image , CompressedImage
import cv2
import numpy as np
from cv_bridge import CvBridge
from ultralytics import YOLO  # Ensure YOLOv8 or compatible version is installed
import pyrealsense2 as rs

model_file = "/app/augmented-robots/server/nux_ws/src/smart_robots_controller/config/yolov8n.pt"

model = YOLO(model_file)

class ImageSubscriberYOLO(Node):
    def __init__(self):
        super().__init__('image_subscriber_yolo_tb3')
        self.subscription = self.create_subscription(
            Image,
            '/camera/color/image_raw',
            self.image_callback,
            10
        )
        self.bridge = CvBridge()
        self.yolo_model = model  # Update path to your YOLO model file

    def image_callback(self, msg):
        # Convert ROS Image message to OpenCV image
        cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')

        # Process the image with YOLO
        results = self.yolo_model(cv_image)

        # Render detections
        cv_image = self.render_detections(cv_image, results)

        # Display the image using OpenCV
        cv2.imshow('YOLO Detections', cv_image)
        cv2.waitKey(1)

    def render_detections(self, image, results):
        # Draw bounding boxes and labels on the image
        for r in results:
            boxes = r.boxes
            for box in boxes:
            # bounding box
                #print(box.xyxy[0])
                x1, y1, x2, y2 = box.xyxy[0]
                confidence =box.conf[0]
                cls = int(box.cls[0])

                if model.names[cls] == "person" and confidence > 0.5 : # we can use door or window instead person !!!
                    
                    cv2.rectangle(image , (int(x1),int(y1)) , (int(x2) , int(y2)) , (0,255,0) , 2)


                    (x_center,y_center) = (x2 + x1)/2, (y2+y1)/2 
                    center_coordinates = (int(x_center),int(y_center))

                    try:
                        
                        # zDepth = None  #depth_frame.get_distance(int(x_center),int(y_center))
                        print("Nothing just  ....." )

                    except (AttributeError , NameError):
                        print("Depth unavailable")

                    
                    # print(zDepth)

                    frame_center = (image.shape[1]//2 ,image.shape[0]//2)
                    error_x = center_coordinates[0] - frame_center[0]
                    error_y = center_coordinates[1] - frame_center[1]

                    self.center_coordinates.append(  (int(x_center) , int(y_center) ))

                    # print(f"Error: x ={error_x} , y={error_y}")

                    # center_msg = PointStamped()
                    # center_msg.header.stamp = self.get_clock().now().to_msg()
                    # center_msg.point.x = x_center
                    # center_msg.point.y = y_center
                    # self.center_pub.publish(center_msg)
                    # self.get_logger().info(f"Center coordinates : ({x_center} , {y_center})")
                    
                    if center_coordinates is not None :
            
                        cv2.circle(image, center_coordinates, 5, (0,0,255), 5)
                
               

        cv2.imshow('RealSense Image subscriber', image)
        cv2.waitKey(1)

def main(args=None):
    rclpy.init(args=args)
    node = ImageSubscriberYOLO()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass  # Handle Ctrl+C gracefully
    finally:
        node.destroy_node()
        rclpy.shutdown()
        cv2.destroyAllWindows()

if __name__ == '__main__':
    main()

what i want is to create a node containe a subscriber to /camera/color/image_raw from rs_launch in the same node create a publisher with a compressed image and resduce the qualite in the topic 'new/camera/image_raw you can forget the part whene we calculate the depth and center cordinate 




import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, CompressedImage
import cv2
import numpy as np
from cv_bridge import CvBridge

class ImageProcessor(Node):
    def __init__(self):
        super().__init__('image_processor')
        # Subscribe to the uncompressed image topic
        self.subscription = self.create_subscription(
            Image,
            '/camera/color/image_raw',
            self.image_callback,
            10
        )
        self.publisher_ = self.create_publisher(
            CompressedImage,
            '/new/camera/image_raw',
            10
        )
        self.bridge = CvBridge()

    def image_callback(self, msg):
        # Convert ROS Image message to OpenCV image
        cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')

        # Compress the image to JPEG with reduced quality
        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 50]  # Quality range from 0 to 100 (lower means more compression and less quality)
        result, encimg = cv2.imencode('.jpg', cv_image, encode_param)
        if not result:
            raise RuntimeError("Could not encode image!")

        # Prepare and publish the compressed image
        compressed_msg = CompressedImage()
        compressed_msg.header = msg.header  # Maintain timestamp and frame id
        compressed_msg.format = "jpeg"
        compressed_msg.data = np.array(encimg).tobytes()
        self.publisher_.publish(compressed_msg)
        self.get_logger().info('Published compressed image with reduced quality')

def main(args=None):
    rclpy.init(args=args)
    image_processor = ImageProcessor()
    try:
        rclpy.spin(image_processor)
    except KeyboardInterrupt:
        pass  # Handle Ctrl+C gracefully
    finally:
        image_processor.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()











import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
import cv2
import numpy as np
from cv_bridge import CvBridge
from ultralytics import YOLO  # Ensure YOLOv8 or compatible version is installed

class ImageSubscriberYOLO(Node):
    def __init__(self):
        super().__init__('image_subscriber_yolo')
        self.subscription = self.create_subscription(
            Image,
            '/camera/color/image_raw',
            self.image_callback,
            10
        )
        self.bridge = CvBridge()
        self.yolo_model = YOLO('/path/to/yolov8n.pt')  # Update path to your YOLO model file

    def image_callback(self, msg):
        # Convert ROS Image message to OpenCV image
        cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')

        # Process the image with YOLO
        results = self.yolo_model(cv_image)

        # Render detections
        cv_image = self.render_detections(cv_image, results)

        # Display the image using OpenCV
        cv2.imshow('YOLO Detections', cv_image)
        cv2.waitKey(1)

    def render_detections(self, image, results):
        # Draw bounding boxes and labels on the image
        for result in results.xyxy[0]:  # results.xyxy[0] contains bbox coordinates
            if result[-1] > 0.3:  # Confidence threshold
                x1, y1, x2, y2, conf, cls_id = result
                cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)
                cv2.putText(image, f'{self.yolo_model.names[int(cls_id)]} {conf:.2f}', 
                            (int(x1), int(y1-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,0,0), 2)
        return image

def main(args=None):
    rclpy.init(args=args)
    node = ImageSubscriberYOLO()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass  # Handle Ctrl+C gracefully
    finally:
        node.destroy_node()
        rclpy.shutdown()
        cv2.destroyAllWindows()

if __name__ == '__main__':
    main()



import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
import cv2
import pyrealsense2 as rs
import numpy as np

class ImagePublisher(Node):
    def __init__(self):
        super().__init__('image_publisher')
        self.publisher_ = self.create_publisher(Image, '/camera/image_raw', 10)
        self.bridge = CvBridge()

        # Initialize the camera
        self.pipeline = rs.pipeline()
        config = rs.config()

        # Match the configuration with rs_launch parameters
        config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)  # Depth stream
        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)  # Color stream

        # Start the camera pipeline with a context manager to handle exceptions
        try:
            self.pipeline.start(config)
            self.get_logger().info("RealSense camera started successfully.")
        except Exception as e:
            self.get_logger().error(f"Failed to start the camera pipeline: {str(e)}")
            return  # Stop initialization if the camera fails to start

        self.timer_period = 0.1  # seconds
        self.timer = self.create_timer(self.timer_period, self.timer_callback)

    def timer_callback(self):
        try:
            frames = self.pipeline.wait_for_frames()
            depth_frame = frames.get_depth_frame()
            color_frame = frames.get_color_frame()
        except Exception as e:
            self.get_logger().error(f"Failed to get frames: {str(e)}")
            return

        if not depth_frame or not color_frame:
            self.get_logger().warn("Incomplete frames received")
            return

        # Convert color frame to ROS Image message and publish
        color_image = np.asanyarray(color_frame.get_data())
        msg = self.bridge.cv2_to_imgmsg(color_image, encoding="bgr8")
        msg.header.stamp = self.get_clock().now().to_msg()
        self.publisher_.publish(msg)

def main(args=None):
    rclpy.init(args=args)
    image_publisher = ImagePublisher()
    try:
        rclpy.spin(image_publisher)
    finally:
        image_publisher.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()



import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
import cv2
import pyrealsense2 as rs
import numpy as np

class ImagePublisher(Node):
    def __init__(self):
        super().__init__('image_publisher')
        self.publisher_ = self.create_publisher(Image, '/camera/image_raw', 10)
        self.bridge = CvBridge()

        # Initialize the camera
        self.pipeline = rs.pipeline()
        config = rs.config()

        # Configure the RealSense to use a lower resolution for color and depth to ensure compatibility
        config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 15)  # Lower FPS to 15
        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 15)

        # Start the camera pipeline
        try:
            self.pipeline.start(config)
            self.get_logger().info("RealSense camera started successfully.")
        except Exception as e:
            self.get_logger().error(f"Failed to start the camera pipeline: {str(e)}")
        
        self.timer_period = 0.1  # seconds (10Hz)
        self.timer = self.create_timer(self.timer_period, self.timer_callback)

    def timer_callback(self):
        frames = None
        try:
            frames = self.pipeline.wait_for_frames(5000)  # Wait for a frame for up to 5000 ms
        except Exception as e:
            self.get_logger().error(f"Failed to get frames: {str(e)}")
            return

        depth_frame = frames.get_depth_frame()
        color_frame = frames.get_color_frame()

        if not depth_frame or not color_frame:
            self.get_logger().warn("No frames data received")
            return

        # Process color frame
        color_image = np.asanyarray(color_frame.get_data())
        msg = self.bridge.cv2_to_imgmsg(color_image, encoding="bgr8")
        msg.header.stamp = self.get_clock().now().to_msg()
        self.publisher_.publish(msg)
        self.get_logger().info("Published a new image.")

def main(args=None):
    rclpy.init(args=args)
    image_publisher = ImagePublisher()
    rclpy.spin(image_publisher)
    image_publisher.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()





import rclpy
from rclpy.node import Node
from sensor_msgs.msg import CompressedImage
import cv2
import numpy as np
from cv_bridge import CvBridge

class SimpleImageSubscriber(Node):
    def __init__(self):
        super().__init__('simple_image_subscriber')
        self.subscription = self.create_subscription(
            CompressedImage,
            '/camera/image_raw/compressed',
            self.image_callback,
            10
        )
        self.bridge = CvBridge()

    def image_callback(self, msg):
        try:
            # Convert the compressed image ROS message to a format that OpenCV can use
            cv_image = self.bridge.compressed_imgmsg_to_cv2(msg, desired_encoding='bgr8')

            # Display the image using OpenCV
            cv2.imshow('Camera Image', cv_image)
            cv2.waitKey(1)  # Wait for a key press for 1 millisecond

        except Exception as e:
            self.get_logger().error('Failed to convert image: %s' % str(e))

def main(args=None):
    rclpy.init(args=args)
    node = SimpleImageSubscriber()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()
        cv2.destroyAllWindows()  # Make sure to destroy all OpenCV windows

if __name__ == '__main__':
    main()



import rclpy 
from rclpy.node import Node 
from sensor_msgs.msg import Image 
from geometry_msgs.msg import PointStamped
from cv_bridge import CvBridge 
import cv2 
import pyrealsense2 as rs
import numpy as np
 
class ImagePublisher(Node):
 
  def __init__(self):
 
  
    super().__init__('image_publisher')

    self.publisher_ = self.create_publisher(Image, '/camera/image_raw/compressed', 10) 
    self.bridge = CvBridge()
    self.center_sub = self.create_subscription(PointStamped , '/image/center_coordinates' , self.center_callback ,10)
    self.depth_pub = self.create_publisher(PointStamped , '/image/zDepth' , 10)

    self.pipeline =  rs.pipeline()
    config = rs.config()
    config.enable_stream(rs.stream.depth , 640 ,480 , rs.format.z16 , 30)
    config.enable_stream(rs.stream.color , 640 ,480 , rs.format.bgr8 , 30) # FPS = 30 

    self.pipeline.start(config)

  
    self.timer_period = 0.1  
    self.timer = self.create_timer(self.timer_period , self.timer_callback)
    self.x_center = None
    self.y_center = None 

  def timer_callback(self):
    frames = self.pipeline.wait_for_frames()  
    depth_frame = frames.get_depth_frame()
    color_frame = frames.get_color_frame()
    depth_frame = frames.get_depth_frame()
    if color_frame:
      color_image = np.asanyarray(color_frame.get_data()) 
      #rgb_image = cv2.cvtColor(color_image , cv2.COLOR_BGR2RGB)
 
    
#      if self.center_sub:
#          if self.center_x is not None and self.center_y is not None:
#            print(f"Center Coordinates : ({self.center_x} , {self.center_y})")
   
      _ , compressed_image_data = cv2.imencode('.jpg' , color_image , [cv2.IMWRITE_JPEG_QUALITY , 20])
      compressed_image_data  = compressed_image_data.tobytes()
      
      msg = Image()
      msg.header.stamp = self.get_clock().now().to_msg()

      msg.data = compressed_image_data 
      msg.encoding = 'jpeg'

      self.publisher_ .publish(msg) 
#      self.timer_callback(self.x_center , self.y_center)
    if self.x_center is not None and self.y_center is not None:
      zDepth = depth_frame.get_distance(int(self.x_center),int(self.y_center))
      depth_msg = PointStamped()
      depth_msg.header.stamp = self.get_clock().now().to_msg()
      depth_msg.point.x = self.x_center
      depth_msg.point.y = self.y_center
      depth_msg.point.z = zDepth
      self.depth_pub.publish(depth_msg)
      self.get_logger().info(f"Depth is  : {zDepth}")
  
  def center_callback(self ,msg):
#                  
    self.x_center = msg.point.x
    self.y_center = msg.point.y
#    zDepth = depth_frame.get_distance(int(self.x_center),int(self.y_center))
#    self.center_callback(self.x_center ,self.y_center)
#    self.get_logger().info(f"Depth is  : {zDepth})")
#    self.get_logger().info('I heard: "%s"' % msg.zDepth)
   
def main(args=None):

  rclpy.init(args=args)
  

  image_publisher = ImagePublisher()

  rclpy.spin(image_publisher)
  
  rclpy.shutdown()
  
if __name__ == '__main__':
  main()






import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from geometry_msgs.msg import PointStamped
import cv2
import numpy as np
from cv_bridge import CvBridge
from ultralytics import YOLO
import open3d as o3d 
from ament_index_python.packages import get_package_share_directory
import pyrealsense2 as rs
import os


# smart_robots_dir = get_package_share_directory("smart_robots_controller")
# model_file = os.path.join(smart_robots_dir, "config", "yolov8n.pt")
model_file = "/app/augmented-robots/server/nux_ws/src/smart_robots_controller/config/yolov8n.pt"

model = YOLO(model_file)
class ImageSubscriber(Node):

    def __init__(self):
        super().__init__('image_subscriber_yolo')
        self.image_sub = self.create_subscription(Image, '/camera/image_raw/compressed', self.image_callback, 10)
        self.depth_sub = self.create_subscription(PointStamped, 'image/zDepth', self.zDepth_callback, 10)

        self.bridge = CvBridge()

        timer_period = 0.5

        self.center_pub = self.create_publisher(PointStamped , '/image/center_coordinates' , 10)
        self.timer = self.create_timer(timer_period, self.timer_callback)
        self.i = 0
        self.center_coordinates = []


    

    def image_callback(self, msg):
        # global center_coordinates


        decoded_data = np.frombuffer(msg.data, dtype=np.uint8)
        decoded_image = cv2.imdecode(decoded_data, cv2.IMREAD_COLOR) 

        rbg_image = cv2.cvtColor(decoded_image , cv2.COLOR_BGR2RGB)

        results = model(rbg_image)
        results = model.predict(source=rbg_image, show=False, stream=True, verbose=False) 

        for r in results:
            boxes = r.boxes
            for box in boxes:
            # bounding box
                #print(box.xyxy[0])
                x1, y1, x2, y2 = box.xyxy[0]
                confidence =box.conf[0]
                cls = int(box.cls[0])

                if model.names[cls] == "person" and confidence > 0.5 : # we can use door or window instead person !!!
                    
                    cv2.rectangle(decoded_image , (int(x1),int(y1)) , (int(x2) , int(y2)) , (0,255,0) , 2)


                    (x_center,y_center) = (x2 + x1)/2, (y2+y1)/2 
                    center_coordinates = (int(x_center),int(y_center))

                    try:
                        
                        # zDepth = None  #depth_frame.get_distance(int(x_center),int(y_center))
                        print("Nothing just  ....." )

                    except (AttributeError , NameError):
                        print("Depth unavailable")

                    
                    # print(zDepth)

                    frame_center = (rbg_image.shape[1]//2 ,rbg_image.shape[0]//2)
                    error_x = center_coordinates[0] - frame_center[0]
                    error_y = center_coordinates[1] - frame_center[1]

                    self.center_coordinates.append(  (int(x_center) , int(y_center) ))

                    # print(f"Error: x ={error_x} , y={error_y}")

                    # center_msg = PointStamped()
                    # center_msg.header.stamp = self.get_clock().now().to_msg()
                    # center_msg.point.x = x_center
                    # center_msg.point.y = y_center
                    # self.center_pub.publish(center_msg)
                    # self.get_logger().info(f"Center coordinates : ({x_center} , {y_center})")
                    
                    if center_coordinates is not None :
            
                        cv2.circle(decoded_image, center_coordinates, 5, (0,0,255), 5)
                
               

        cv2.imshow('RealSense Image subscriber', decoded_image)
        cv2.waitKey(1)

    def timer_callback(self):


        if len(self.center_coordinates)>0 :

            x_center , y_center = self.center_coordinates[-1]

            msg = PointStamped()
            msg.header.stamp = self. get_clock().now().to_msg()
            msg.point.x = float(x_center)
            msg.point.y = float(y_center)

            self.center_pub.publish(msg)
            self.get_logger().info(f"Publishing center Coordinates: {msg.point.x} ,{msg.point.y}")
            self.i += 1
        else:
            self.get_logger().info('No center Coordinates:')

    def zDepth_callback(self ,msg):

        msg = PointStamped()
        msg.header.stamp = self.get_clock().now().to_msg()
        # msg.point.z = float(x_center)
        # x_center  =center_msg.point.x
        # y_center =center_msg.point.y
        zDepth  = msg.point.z

        self.get_logger().info(f"Publishing zDepth value: {zDepth}")
        

 



def main():
    rclpy.init()
    node = ImageSubscriber()
    rclpy.spin(node)
    rclpy.shutdown()

if __name__ == '__main__':
    main()
