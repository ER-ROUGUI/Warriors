






import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from geometry_msgs.msg import PointStamped
import cv2
import numpy as np
from cv_bridge import CvBridge
from ultralytics import YOLO
import open3d as o3d 
import pyrealsense2 as rs


model = YOLO("yolov8n.pt")
class ImageSubscriber(Node):

    def __init__(self):
        super().__init__('image_subscriber_yolo')
        self.image_sub = self.create_subscription(Image, '/camera/image_raw/compressed', self.image_callback, 10)
        self.bridge = CvBridge()

        timer_period = 0.5

        self.center_pub = self.create_publisher(PointStamped , '/image/center_coordinates' , 10)
        self.timer = self.create_timer(timer_period, self.timer_callback)
        self.i = 0
        self.center_coordinates = None


    

    def image_callback(self, msg):
        global center_coordinates


        decoded_data = np.frombuffer(msg.data, dtype=np.uint8)
        decoded_image = cv2.imdecode(decoded_data, cv2.IMREAD_COLOR) 

        rbg_image = cv2.cvtColor(decoded_image , cv2.COLOR_BGR2RGB)

        result = model(rbg_image)
        results = model.predict(source=rbg_image, show=False, stream=True, verbose=False) 

        for r in results:
            boxes = r.boxes
            for box in boxes:
            # bounding box
                #print(box.xyxy[0])
                x1, y1, x2, y2 = box.xyxy[0]
                confidence =box.conf[0]
                cls = int(box.cls[0])

                if model.names[cls] == "person" and confidence > 0.5 : # we can use door or window instead person !!!
                    
                    cv2.rectangle(decoded_image , (int(x1),int(y1)) , (int(x2) , int(y2)) , (0,255,0) , 2)


                    (x_center,y_center) = (x2 + x1)/2, (y2+y1)/2 
                    center_coordinates = (int(x_center),int(y_center))

                    try:
                        
                        zDepth = None#depth_frame.get_distance(int(x_center),int(y_center))
                        print(f"Depth at center : {zDepth}" )

                    except (AttributeError , NameError):
                        print("Depth unavailable")

                    
                    # print(zDepth)

                    frame_center = (rbg_image.shape[1]//2 ,rbg_image.shape[0]//2)
                    error_x = center_coordinates[0] - frame_center[0]
                    error_y = center_coordinates[1] - frame_center[1]

                    print(f"Error: x ={error_x} , y={error_y}")

                    # center_msg = PointStamped()
                    # center_msg.header.stamp = self. get_clock().now().to_msg()
                    # center_msg.point.x = x_center
                    # center_msg.point.y = y_center
                    # self.center_pub.publish(center_msg)
                    # self.get_logger().info(f"Center coordinates : ({x_center} , {y_center})")
                    
                    if center_coordinates is not None :
            
                        cv2.circle(decoded_image, center_coordinates, 5, (0,0,255), 5)
                
           

        cv2.imshow('RealSense Image', decoded_image)
        cv2.waitKey(1)

    def timer_callback(self):
        msg = PointStamped()
        msg.header.stamp = self. get_clock().now().to_msg()
        msg.point.x = float(self.center_coordinates[0])
        msg.point.y = float(self.center_coordinates[1])

        self.publisher_.publish(msg)
        self.get_logger().info('Publishing: "%s"' % msg.data)
        self.i += 1

def main():
    rclpy.init()
    node = ImageSubscriber()
    rclpy.spin(node)
    rclpy.shutdown()

if __name__ == '__main__':
    main()






























import rclpy 
from rclpy.node import Node 
from sensor_msgs.msg import Image 
from cv_bridge import CvBridge 
import cv2 
import pyrealsense2 as rs
import numpy as np
 
class ImagePublisher(Node):
 
  def __init__(self):
 
  
    super().__init__('image_publisher')

    self.publisher_ = self.create_publisher(Image, '/camera/image_raw/compressed', 10) 
    self.bridge = CvBridge()
    self.pipeline =  rs.pipeline()
    config = rs.config()
    config.enable_stream(rs.stream.depth , 640 ,480 , rs.format.z16 , 30)
    config.enable_stream(rs.stream.color , 640 ,480 , rs.format.bgr8 , 30)

    self.pipeline.start(config)

  
    timer_period = 0.1  
      
    
    self.timer = self.create_timer(timer_period, self.timer_callback)
         
 
  def timer_callback(self):

    frames = self.pipeline.wait_for_frames()
    color_frame = frames.get_color_frame()
    if color_frame:
      color_image = np.asanyarray(color_frame.get_data()) 
      #rgb_image = cv2.cvtColor(color_image , cv2.COLOR_BGR2RGB) 
      _ , compressed_image_data = cv2.imencode('.jpg' , color_image , [cv2.IMWRITE_JPEG_QUALITY , 25])
      compressed_image_data  = compressed_image_data.tobytes()
      
      msg = Image()
      msg.header.stamp = self.get_clock().now().to_msg()

      msg.data = compressed_image_data 
      msg.encoding = 'jpeg'

      self.publisher_ .publish(msg)        
  
def main(args=None):

  rclpy.init(args=args)
  

  image_publisher = ImagePublisher()

  rclpy.spin(image_publisher)
  
  rclpy.shutdown()
  
if __name__ == '__main__':
  main()





import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from geometry_msgs.msg import PointStamped
import cv2
import numpy as np
from cv_bridge import CvBridge
from ultralytics import YOLO
import open3d as o3d 
import pyrealsense2 as rs


model = YOLO("yolov8n.pt")
class ImageSubscriber(Node):

    def __init__(self):
        super().__init__('image_subscriber_yolo')
        self.image_sub = self.create_subscription(Image, '/camera/image_raw/compressed', self.image_callback, 10)
        self.bridge = CvBridge()

        self.center_pub = self.create_publisher(PointStamped , '/image/center_coordinates' , 10)


        

    def image_callback(self, msg):


        decoded_data = np.frombuffer(msg.data, dtype=np.uint8)
        decoded_image = cv2.imdecode(decoded_data, cv2.IMREAD_COLOR) 

        rbg_image = cv2.cvtColor(decoded_image , cv2.COLOR_BGR2RGB)

        result = model(rbg_image)
        results = model.predict(source=rbg_image, show=False, stream=True, verbose=False) 

        for r in results:
            boxes = r.boxes
            for box in boxes:
            # bounding box
                #print(box.xyxy[0])
                x1, y1, x2, y2 = box.xyxy[0]
                confidence =box.conf[0]
                cls = int(box.cls[0])

                if model.names[cls] == "person" and confidence > 0.5 : # we can use door or window instead person !!!
                    
                    cv2.rectangle(decoded_image , (int(x1),int(y1)) , (int(x2) , int(y2)) , (0,255,0) , 2)


                    (x_center,y_center) = (x2 + x1)/2, (y2+y1)/2 
                    center_coordinates = (int(x_center),int(y_center))

                    try:
                        
                        zDepth = 1#depth_frame.get_distance(int(x_center),int(y_center))
                        print(f"Depth at center : {zDepth}" )

                    except (AttributeError , NameError):
                        print("Depth unavailable")

                    
                    # print(zDepth)

                    frame_center = (rbg_image.shape[1]//2 ,rbg_image.shape[0]//2)
                    error_x = center_coordinates[0] - frame_center[0]
                    error_y = center_coordinates[1] - frame_center[1]

                    print(f"Error: x ={error_x} , y={error_y}")

                    center_msg = PointStamped()
                    center_msg.header.stamp = self. get_clock().now().to_msg()
                    center_msg.point.x = x_center
                    center_msg.point.y = y_center
                    self.center_pub.publish(center_msg)
                    self.get_logger().info(f"Center coordinates : ({x_center} , {y_center})")
                    
                    if center_coordinates is not None :
            
                        cv2.circle(decoded_image, center_coordinates, 5, (0,0,255), 5)
                
    

        cv2.imshow('RealSense Image', decoded_image)
        cv2.waitKey(1)

def main():
    rclpy.init()
    node = ImageSubscriber()
    rclpy.spin(node)
    rclpy.shutdown()

if __name__ == '__main__':
    main()



import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
import cv2
import numpy as np
from cv_bridge import CvBridge
from ultralytics import YOLO
import open3d as o3d 
import pyrealsense2 as rs


model = YOLO("yolov8n.pt")
class ImageSubscriber(Node):

    def __init__(self):
        super().__init__('image_subscriber_yolo')
        self.image_sub = self.create_subscription(Image, '/camera/image_raw/compressed', self.image_callback, 10)
        self.bridge = CvBridge()

        

    def image_callback(self, msg):


        decoded_data = np.frombuffer(msg.data, dtype=np.uint8)
        decoded_image = cv2.imdecode(decoded_data, cv2.IMREAD_COLOR) 

        rbg_image = cv2.cvtColor(decoded_image , cv2.COLOR_BGR2RGB)

        result = model(rbg_image)
        results = model.predict(source=rbg_image, show=False, stream=True, verbose=False) 

        for r in results:
            boxes = r.boxes
            for box in boxes:
            # bounding box
                #print(box.xyxy[0])
                x1, y1, x2, y2 = box.xyxy[0]
                confidence =box.conf[0]
                cls = int(box.cls[0])

                if model.names[cls] == "person" and confidence > 0.5 : # we can use door or window instead person !!!
                    
                    cv2.rectangle(decoded_image , (int(x1),int(y1)) , (int(x2) , int(y2)) , (0,255,0) , 2)


                    (x_center,y_center) = (x2 + x1)/2, (y2+y1)/2 
                    center_coordinates = (int(x_center),int(y_center))

                    try:
                        
                        zDepth = 1#depth_frame.get_distance(int(x_center),int(y_center))
                        print(f"Depth at center : {zDepth}" )

                    except (AttributeError , NameError):
                        print("Depth unavailable")

                    
                    # print(zDepth)

                    frame_center = (rbg_image.shape[1]//2 ,rbg_image.shape[0]//2)
                    error_x = center_coordinates[0] - frame_center[0]
                    error_y = center_coordinates[1] - frame_center[1]

                    print(f"Error: x ={error_x} , y={error_y}")
                    if center_coordinates is not None :
            
                        cv2.circle(decoded_image, center_coordinates, 5, (0,0,255), 5)
                
    

        cv2.imshow('RealSense Image', decoded_image)
        cv2.waitKey(1)

def main():
    rclpy.init()
    node = ImageSubscriber()
    rclpy.spin(node)
    rclpy.shutdown()

if __name__ == '__main__':
    main()




import rclpy 
from rclpy.node import Node 
from sensor_msgs.msg import Image 
from cv_bridge import CvBridge 
import cv2 
import pyrealsense2 as rs
import numpy as np
 
class ImagePublisher(Node):
 
  def __init__(self):
 
  
    super().__init__('image_publisher')

    self.publisher_ = self.create_publisher(Image, '/camera/image_raw/compressed', 10) 
    self.bridge = CvBridge()
    self.pipeline =  rs.pipeline()
    config = rs.config()
    config.enable_stream(rs.stream.depth , 640 ,480 , rs.format.z16 , 30)
    config.enable_stream(rs.stream.color , 640 ,480 , rs.format.bgr8 , 30)

    self.pipeline.start(config)

  
    timer_period = 0.1  
      
    
    self.timer = self.create_timer(timer_period, self.timer_callback)
         
 
  def timer_callback(self):

    frames = self.pipeline.wait_for_frames()
    color_frame = frames.get_color_frame()
    if color_frame:
      color_image = np.asanyarray(color_frame.get_data()) 
      #rgb_image = cv2.cvtColor(color_image , cv2.COLOR_BGR2RGB) 
      _ , compressed_image_data = cv2.imencode('.jpg' , color_image , [cv2.IMWRITE_JPEG_QUALITY , 25])
      compressed_image_data  = compressed_image_data.tobytes()
      
      msg = Image()
      msg.header.stamp = self.get_clock().now().to_msg()

      msg.data = compressed_image_data 
      msg.encoding = 'jpeg'

      self.publisher_ .publish(msg)        
  
def main(args=None):

  rclpy.init(args=args)
  

  image_publisher = ImagePublisher()

  rclpy.spin(image_publisher)
  
  rclpy.shutdown()
  
if __name__ == '__main__':
  main()



#!/usr/bin/env python3
from ultralytics import YOLO
import cv2
import math 
import open3d as o3d 
import numpy as np
import pyrealsense2 as rs
# start webcam


pipeline = rs.pipeline()
config = rs.config()
config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 6)
profile = pipeline.start(config)


# cap = cv2.VideoCapture(4)
# cap.set(3, 640)
# cap.set(4, 480)

# model
model = YOLO("yolov8n.pt")

# classNames = ["person"
#               ]

try:
    while True :
        frames = pipeline.wait_for_frames()
        color_frame =frames.get_color_frame()
        depth_frame = frames.get_depth_frame()
        if not color_frame :
            continue
        

   



        depth_image = np.asanyarray(depth_frame.get_data())
        # print(type(depth_image))
        # print("depth_frame " , type(depth_frame))
        intrinsic= profile.get_stream(rs.stream.color).as_video_stream_profile().get_intrinsics()
        pinhole_camera_intrinsic = o3d.camera.PinholeCameraIntrinsic(intrinsic.width, intrinsic.height, intrinsic.fx, intrinsic.fy, intrinsic.ppx, intrinsic.ppy)
        image = np.asanyarray(color_frame.get_data())

        resultes = model(image)
        results = model.predict(source=image, show=True, stream=True, verbose=False)  # set the show on True to show automaticlly the bbox


        for r in results:
            boxes = r.boxes
            for box in boxes:
            # bounding box
                #print(box.xyxy[0])
                x1, y1, x2, y2 = box.xyxy[0]
                (x_center,y_center) = (x2 + x1)/2, (y2+y1)/2 
                center_coordinates = (int(x_center),int(y_center))
                zDepth = depth_frame.get_distance(int(x_center),int(y_center))
                
                print(center_coordinates)

                # cls = int(box.cls[0])
                # print("Class name -->", classNames[cls])
                
        #         x1, y1, x2,s y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values

        #     # put box in cam
        #     cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 255), 3)
            cv2.circle(image, center_coordinates, 5, (0,0,255), 5)
        
        cv2.imshow('Webcam', image)
        if cv2.waitKey(1)& 0xFF == ord('q'):
            break
finally:

    pipeline.stop()
    cv2.destroyAllWindows()

# # object classes
# classNames = ["person", "bicycle", "car", "motorbike", "aeroplane", "bus", "train", "truck", "boat",
#               "traffic light", "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat",
#               "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack", "umbrella",
#               "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sports ball", "kite", "baseball bat",
#               "baseball glove", "skateboard", "surfboard", "tennis racket", "bottle", "wine glass", "cup",
#               "fork", "knife", "spoon", "bowl", "banana", "apple", "sandwich", "orange", "broccoli",
#               "carrot", "hot dog", "pizza", "donut", "cake", "chair", "sofa", "pottedplant", "bed",
#               "diningtable", "toilet", "tvmonitor", "laptop", "mouse", "remote", "keyboard", "cell phone",
#               "microwave", "oven", "toaster", "sink", "refrigerator", "book", "clock", "vase", "scissors",
#               "teddy bear", "hair drier", "toothbrush"
#               ]


# while True:
#     success, img = cap.read()
#     results = model(img, stream=True)

#     # coordinates
#     for r in results:
#         boxes = r.boxes

#         for box in boxes:
#             # bounding box
#             x1, y1, x2, y2 = box.xyxy[0]
#             x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values

#             # put box in cam
#             cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)

#             # confidence
#             confidence = math.ceil((box.conf[0]*100))/100
#             print("Confidence --->",confidence)

#             # class name
#             cls = int(box.cls[0])
#             print("Class name -->", classNames[cls])

#             # object details
#             org = [x1, y1]
#             font = cv2.FONT_HERSHEY_SIMPLEX
#             fontScale = 1
#             color = (255, 0, 0)
#             thickness = 2

#             cv2.putText(img, classNames[cls], org, font, fontScale, color, thickness)

#     cv2.imshow('Webcam', img)
#     if cv2.waitKey(1) == ord('q'):
#         break

# cap.release()
# cv2.destroyAllWindows()
import cv2
import numpy as np
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from cv_bridge import CvBridge

class ImagePublisher(Node):
    def __init__(self):
        super().__init__('image_publisher')
        self.publisher_ = self.create_publisher(Image, 'image_topic', 10)
        self.timer_ = self.create_timer(1.0 / 30, self.publish_image)  # adjust the rate as needed
        self.bridge = CvBridge()

    def publish_image(self):
        # Read frames from RealSense camera
        frames = pipeline.wait_for_frames()
        color_frame = frames.get_color_frame()
        if not color_frame:
            return

        # Convert RealSense frame to OpenCV format
        image = np.asanyarray(color_frame.get_data())

        # Convert OpenCV image to ROS image
        ros_image = self.bridge.cv2_to_imgmsg(image, 'bgr8')

        # Publish the ROS image
        self.publisher_.publish(ros_image)


def main(args=None):
    rclpy.init(args=args)

    image_publisher = ImagePublisher()

    rclpy.spin(image_publisher)

    image_publisher.destroy_node()
    rclpy.shutdown()


if __name__ == '__main__':
    main()


import cv2
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from cv_bridge import CvBridge

class ImageSubscriber(Node):
    def __init__(self):
        super().__init__('image_subscriber')
        self.subscription = self.create_subscription(
            Image,
            'image_topic',
            self.image_callback,
            10
        )
        self.subscription  # prevent unused variable warning
        self.bridge = CvBridge()

    def image_callback(self, msg):
        # Convert ROS image to OpenCV format
        image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')

        # Display the image using OpenCV
        cv2.imshow('Received Image', image)
        cv2.waitKey(1)  # Adjust as needed to display the image

def main(args=None):
    rclpy.init(args=args)

    image_subscriber = ImageSubscriber()

    rclpy.spin(image_subscriber)

    image_subscriber.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()


import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
import cv2
import numpy as np
from cv_bridge import CvBridge

class ImagePublisher(Node):

    def __init__(self):
        super().__init__('image_publisher')
        self.image_pub = self.create_publisher(Image, '/camera/image_raw/compressed')
        self.bridge = CvBridge()
        self.pipeline = rs.pipeline()

        # Configure RealSense pipeline (replace with your desired settings)
        config = rs.config()
        config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)

        # Start streaming
        self.pipeline.start(config)

        # Timer to capture and publish images
        self.timer = self.create_timer(0.1, self.capture_and_publish)  # Adjust interval as needed

    def capture_and_publish(self):
        frames = self.pipeline.wait_for_frames()
        color_frame = frames.get_color_frame()

        if color_frame:
            # Convert to OpenCV image
            color_image = np.asanyarray(color_frame.get_data())

            # Compress image (adjust parameters as needed)
            _, compressed_image_data = cv2.imencode('.jpg', color_image, [cv2.IMWRITE_JPEG_QUALITY, 75])
            compressed_image_data = compressed_image_data.tobytes()

            # Create ROS Image message
            msg = Image()
            msg.header.stamp = self.get_clock().now()
            msg.data = compressed_image_data
            msg.encoding = 'jpeg'  # Adjust encoding based on compression format

            self.image_pub.publish(msg)

def main():
    rclpy.init()
    node = ImagePublisher()
    rclpy.spin(node)
    rclpy.shutdown()

if __name__ == '__main__':
    main()

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
import cv2
import numpy as np
from cv_bridge import CvBridge

class ImageSubscriber(Node):

    def __init__(self):
        super().__init__('image_subscriber')
        self.image_sub = self.create_subscription(Image, '/camera/image_raw/compressed', self.image_callback, 10)
        self.bridge = CvBridge()

    def image_callback(self, msg):
        # Decompress image (adjust parameters as needed)
        decoded_data = np.frombuffer(msg.data, dtype=np.uint8)
        decoded_image = cv2.imdecode(decoded_data, cv2.IMREAD_COLOR)  # Adjust decoding based on compression format

        # Display the received image
        cv2.imshow('RealSense Image', decoded_image)
        cv2.waitKey(1)

def main():
    rclpy.init()
    node = ImageSubscriber()
    rclpy.spin(node)
    rclpy.shutdown()

if __name__ == '__main__':
    main()
######################################################################


import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
import cv2
import numpy as np
from cv_bridge import CvBridge
from ultralytics import YOLO
import open3d as o3d 


model = YOLO("yolov8n.pt")
class ImageSubscriber(Node):

    def __init__(self):
        super().__init__('image_subscriber_yolo')
        self.image_sub = self.create_subscription(Image, '/camera/image_raw/compressed', self.image_callback, 10)
        self.bridge = CvBridge()

    def image_callback(self, msg):

        decoded_data = np.frombuffer(msg.data, dtype=np.uint8)
        decoded_image = cv2.imdecode(decoded_data, cv2.IMREAD_COLOR) 

        rbg_image = cv2.cvtColor(decoded_image , cv2.COLOR_BGR2RGB)

        result = model(rbg_image)
        results = model.predict(source=rbg_image, show=True, stream=True, verbose=False) 

        for r in results:
            boxes = r.boxes
            for box in boxes:
            # bounding box
                #print(box.xyxy[0])
                x1, y1, x2, y2 = box.xyxy[0]
                confidence =box.conf[0]
                cls = int(box.cls[0])

                if model.names[cls] == "person" and confidence > 0.5 : # we can use door or window instead person !!!
                    cv2.rectangle(rbg_image , (int(x1),int(y1)) , (int(x2) , int(y2)) , (0,255,0) , 2)


                    (x_center,y_center) = (x2 + x1)/2, (y2+y1)/2 
                    center_coordinates = (int(x_center),int(y_center))
                    # zDepth = depth_frame.get_distance(int(x_center),int(y_center))
                    
                    # print(zDepth)

                    frame_center = (rbg_image.shape[1]//2 ,rbg_image.shape[0]//2)
                    error_x = center_coordinates[0] - frame_center[0]
                    error_y = center_coordinates[1] - frame_center[1]

                    print(f"Error: x ={error_x} , y={error_y}")
            cv2.circle(decoded_image, center_coordinates, 5, (0,0,255), 5)

        cv2.imshow('RealSense Image', decoded_image)
        cv2.waitKey(1)

def main():
    rclpy.init()
    node = ImageSubscriber()
    rclpy.spin(node)
    rclpy.shutdown()

if __name__ == '__main__':
    main()

############################

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
import cv2
import numpy as np
from cv_bridge import CvBridge
from ultralytics import YOLO
import open3d as o3d 


model = YOLO("yolov8n.pt")
class ImageSubscriber(Node):

    def __init__(self):
        super().__init__('image_subscriber_yolo')
        self.image_sub = self.create_subscription(Image, '/camera/image_raw/compressed', self.image_callback, 10)
        self.bridge = CvBridge()

    def image_callback(self, msg):

        decoded_data = np.frombuffer(msg.data, dtype=np.uint8)
        decoded_image = cv2.imdecode(decoded_data, cv2.IMREAD_COLOR) 

        rbg_image = cv2.cvtColor(decoded_image , cv2.COLOR_BGR2RGB)

        result = model(rbg_image)
        results = model.predict(source=rbg_image, show=False, stream=True, verbose=False) 

        for r in results:
            boxes = r.boxes
            for box in boxes:
            # bounding box
                #print(box.xyxy[0])
                x1, y1, x2, y2 = box.xyxy[0]
                confidence =box.conf[0]
                cls = int(box.cls[0])

                if model.names[cls] == "person" and confidence > 0.5 : # we can use door or window instead person !!!
                    
                    cv2.rectangle(decoded_image , (int(x1),int(y1)) , (int(x2) , int(y2)) , (0,255,0) , 2)


                    (x_center,y_center) = (x2 + x1)/2, (y2+y1)/2 
                    center_coordinates = (int(x_center),int(y_center))

                    try:
                        
                        zDepth = 1#depth_frame.get_distance(int(x_center),int(y_center))
                        print(f"Depth at center : {zDepth}" )

                    except (AttributeError , NameError):
                        print("Depth unavailable")

                    
                    # print(zDepth)

                    frame_center = (rbg_image.shape[1]//2 ,rbg_image.shape[0]//2)
                    error_x = center_coordinates[0] - frame_center[0]
                    error_y = center_coordinates[1] - frame_center[1]

                    print(f"Error: x ={error_x} , y={error_y}")
                    if center_coordinates is not None :
            
                        cv2.circle(decoded_image, center_coordinates, 5, (0,0,255), 5)
                
    

        cv2.imshow('RealSense Image', decoded_image)
        cv2.waitKey(1)

def main():
    rclpy.init()
    node = ImageSubscriber()
    rclpy.spin(node)
    rclpy.shutdown()

if __name__ == '__main__':
    main()

import rclpy 
from rclpy.node import Node 
from sensor_msgs.msg import Image 
from cv_bridge import CvBridge 
import cv2 
import pyrealsense2 as rs
import numpy as np
 
class ImagePublisher(Node):
 
  def __init__(self):
 
  
    super().__init__('image_publisher')

    self.publisher_ = self.create_publisher(Image, '/camera/image_raw/compressed', 10) 
    self.bridge = CvBridge()
    self.pipeline =  rs.pipeline()
    config = rs.config()
    config.enable_stream(rs.stream.depth , 640 ,480 , rs.format.z16 , 30)
    config.enable_stream(rs.stream.color , 640 ,480 , rs.format.bgr8 , 30)

    self.pipeline.start(config)

  
    timer_period = 0.1  
      
    
    self.timer = self.create_timer(timer_period, self.timer_callback)
         
 
  def timer_callback(self):

    frames = self.pipeline.wait_for_frames()
    color_frame = frames.get_color_frame()
    if color_frame:
      color_image = np.asanyarray(color_frame.get_data()) 
      #rgb_image = cv2.cvtColor(color_image , cv2.COLOR_BGR2RGB) 
      _ , compressed_image_data = cv2.imencode('.jpg' , color_image , [cv2.IMWRITE_JPEG_QUALITY , 25])
      compressed_image_data  = compressed_image_data.tobytes()
      
      msg = Image()
      msg.header.stamp = self.get_clock().now().to_msg()

      msg.data = compressed_image_data 
      msg.encoding = 'jpeg'

      self.publisher_ .publish(msg)        
  
def main(args=None):

  rclpy.init(args=args)
  

  image_publisher = ImagePublisher()

  rclpy.spin(image_publisher)
  
  rclpy.shutdown()
  
if __name__ == '__main__':
  main()

