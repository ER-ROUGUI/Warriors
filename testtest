#!/usr/bin/env python3
from ultralytics import YOLO
import cv2
import math 
import open3d as o3d 
import numpy as np
import pyrealsense2 as rs
# start webcam


pipeline = rs.pipeline()
config = rs.config()
config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 6)
profile = pipeline.start(config)


# cap = cv2.VideoCapture(4)
# cap.set(3, 640)
# cap.set(4, 480)

# model
model = YOLO("yolov8n.pt")

# classNames = ["person"
#               ]

try:
    while True :
        frames = pipeline.wait_for_frames()
        color_frame =frames.get_color_frame()
        depth_frame = frames.get_depth_frame()
        if not color_frame :
            continue
        

   



        depth_image = np.asanyarray(depth_frame.get_data())
        # print(type(depth_image))
        # print("depth_frame " , type(depth_frame))
        intrinsic= profile.get_stream(rs.stream.color).as_video_stream_profile().get_intrinsics()
        pinhole_camera_intrinsic = o3d.camera.PinholeCameraIntrinsic(intrinsic.width, intrinsic.height, intrinsic.fx, intrinsic.fy, intrinsic.ppx, intrinsic.ppy)
        image = np.asanyarray(color_frame.get_data())

        resultes = model(image)
        results = model.predict(source=image, show=True, stream=True, verbose=False)  # set the show on True to show automaticlly the bbox


        for r in results:
            boxes = r.boxes
            for box in boxes:
            # bounding box
                #print(box.xyxy[0])
                x1, y1, x2, y2 = box.xyxy[0]
                (x_center,y_center) = (x2 + x1)/2, (y2+y1)/2 
                center_coordinates = (int(x_center),int(y_center))
                zDepth = depth_frame.get_distance(int(x_center),int(y_center))
                
                print(center_coordinates)

                # cls = int(box.cls[0])
                # print("Class name -->", classNames[cls])
                
        #         x1, y1, x2,s y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values

        #     # put box in cam
        #     cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 255), 3)
            cv2.circle(image, center_coordinates, 5, (0,0,255), 5)
        
        cv2.imshow('Webcam', image)
        if cv2.waitKey(1)& 0xFF == ord('q'):
            break
finally:

    pipeline.stop()
    cv2.destroyAllWindows()

# # object classes
# classNames = ["person", "bicycle", "car", "motorbike", "aeroplane", "bus", "train", "truck", "boat",
#               "traffic light", "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat",
#               "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack", "umbrella",
#               "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sports ball", "kite", "baseball bat",
#               "baseball glove", "skateboard", "surfboard", "tennis racket", "bottle", "wine glass", "cup",
#               "fork", "knife", "spoon", "bowl", "banana", "apple", "sandwich", "orange", "broccoli",
#               "carrot", "hot dog", "pizza", "donut", "cake", "chair", "sofa", "pottedplant", "bed",
#               "diningtable", "toilet", "tvmonitor", "laptop", "mouse", "remote", "keyboard", "cell phone",
#               "microwave", "oven", "toaster", "sink", "refrigerator", "book", "clock", "vase", "scissors",
#               "teddy bear", "hair drier", "toothbrush"
#               ]


# while True:
#     success, img = cap.read()
#     results = model(img, stream=True)

#     # coordinates
#     for r in results:
#         boxes = r.boxes

#         for box in boxes:
#             # bounding box
#             x1, y1, x2, y2 = box.xyxy[0]
#             x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values

#             # put box in cam
#             cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)

#             # confidence
#             confidence = math.ceil((box.conf[0]*100))/100
#             print("Confidence --->",confidence)

#             # class name
#             cls = int(box.cls[0])
#             print("Class name -->", classNames[cls])

#             # object details
#             org = [x1, y1]
#             font = cv2.FONT_HERSHEY_SIMPLEX
#             fontScale = 1
#             color = (255, 0, 0)
#             thickness = 2

#             cv2.putText(img, classNames[cls], org, font, fontScale, color, thickness)

#     cv2.imshow('Webcam', img)
#     if cv2.waitKey(1) == ord('q'):
#         break

# cap.release()
# cv2.destroyAllWindows()
