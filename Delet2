import pyrealsense2 as rs
import numpy as np
import cv2
import os
import time

def capture_images(interval=5, folder='captured_images'):
    # Create the directory to save images if it doesn't exist
    if not os.path.exists(folder):
        os.makedirs(folder)

    # Configure depth and color streams
    pipeline = rs.pipeline()
    config = rs.config()
    
    # Get device product line for setting a supporting resolution
    pipeline_wrapper = rs.pipeline_wrapper(pipeline)
    pipeline_profile = config.resolve(pipeline_wrapper)
    device = pipeline_profile.get_device()
    device_product_line = str(device.get_info(rs.camera_info.product_line))

    found_rgb = False
    for s in device.sensors:
        if s.get_info(rs.camera_info.name) == 'RGB Camera':
            found_rgb = True
            break

    if not found_rgb:
        print("The demo requires Depth camera with Color sensor")
        return

    config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
    
    if device_product_line == 'L500':
        config.enable_stream(rs.stream.color, 960, 540, rs.format.bgr8, 30)
    else:
        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)

    # Start streaming
    pipeline.start(config)

    try:
        image_count = 0
        while True:
            # Wait for a coherent pair of frames: depth and color
            frames = pipeline.wait_for_frames()
            color_frame = frames.get_color_frame()
            if not color_frame:
                continue

            # Convert images to numpy arrays
            color_image = np.asanyarray(color_frame.get_data())

            # Save color image
            img_name = f"{folder}/image_{image_count}.jpg"
            cv2.imwrite(img_name, color_image)
            print(f"Saved {img_name}")

            image_count += 1

            # Sleep for 5 seconds (interval)
            time.sleep(interval)

    finally:
        # Stop streaming
        pipeline.stop()

# Adjust the parameters as needed
capture_images(interval=5, folder='captured_images')







~/libcamera-apps$ meson compile -C build
INFO: autodetecting backend as ninja
INFO: calculating backend command to run: /usr/local/bin/ninja -C /home/orange/libcamera-apps/build
ninja: Entering directory `/home/orange/libcamera-apps/build'
[3/11] Compiling C++ object libcamera_app.so.1.2.2.p/core_libcamera_app.cpp.o
FAILED: libcamera_app.so.1.2.2.p/core_libcamera_app.cpp.o 
c++ -Ilibcamera_app.so.1.2.2.p -I. -I.. -Icore -I/usr/local/include/libcamera -I/usr/include -I/usr/include/x86_64-linux-gnu -I/usr/include/libexif -I/usr/include/libpng16 -I/usr/include/libdrm -I/usr/include/x86_64-linux-gnu/qt5/QtCore -I/usr/include/x86_64-linux-gnu/qt5 -I/usr/include/x86_64-linux-gnu/qt5/QtWidgets -I/usr/include/x86_64-linux-gnu/qt5/QtGui -fdiagnostics-color=always -Wall -Winvalid-pch -Wnon-virtual-dtor -Wextra -Wpedantic -Werror -std=c++17 -O3 -pedantic -Wno-unused-parameter -faligned-new -D_FILE_OFFSET_BITS=64 -Wno-psabi -DLIBAV_PRESENT=1 -DLIBDRM_PRESENT=1 -DQT_PRESENT=1 -fPIC -DQT_WIDGETS_LIB -DQT_GUI_LIB -DQT_CORE_LIB -pthread -DBOOST_ALL_NO_LIB -MD -MQ libcamera_app.so.1.2.2.p/core_libcamera_app.cpp.o -MF libcamera_app.so.1.2.2.p/core_libcamera_app.cpp.o.d -o libcamera_app.so.1.2.2.p/core_libcamera_app.cpp.o -c ../core/libcamera_app.cpp
../core/libcamera_app.cpp: In member function ‘void LibcameraApp::ConfigureViewfinder()’:
../core/libcamera_app.cpp:327:18: error: ‘class libcamera::CameraConfiguration’ has no member named ‘transform’
  327 |  configuration_->transform = options_->transform;
      |                  ^~~~~~~~~
../core/libcamera_app.cpp: In member function ‘void LibcameraApp::ConfigureStill(unsigned int)’:
../core/libcamera_app.cpp:374:18: error: ‘class libcamera::CameraConfiguration’ has no member named ‘transform’
  374 |  configuration_->transform = options_->transform;
      |                  ^~~~~~~~~
../core/libcamera_app.cpp: In member function ‘void LibcameraApp::ConfigureVideo(unsigned int)’:
../core/libcamera_app.cpp:432:18: error: ‘class libcamera::CameraConfiguration’ has no member named ‘transform’
  432 |  configuration_->transform = options_->transform;
      |                  ^~~~~~~~~
../core/libcamera_app.cpp:461:18: error: ‘class libcamera::CameraConfiguration’ has no member named ‘transform’
  461 |  configuration_->transform = options_->transform;
      |                  ^~~~~~~~~
[4/11] Compiling C++ object libcamera_app.so.1.2.2.p/preview_qt_preview.cpp.o
FAILED: libcamera_app.so.1.2.2.p/preview_qt_preview.cpp.o 
c++ -Ilibcamera_app.so.1.2.2.p -I. -I.. -Icore -I/usr/local/include/libcamera -I/usr/include -I/usr/include/x86_64-linux-gnu -I/usr/include/libexif -I/usr/include/libpng16 -I/usr/include/libdrm -I/usr/include/x86_64-linux-gnu/qt5/QtCore -I/usr/include/x86_64-linux-gnu/qt5 -I/usr/include/x86_64-linux-gnu/qt5/QtWidgets -I/usr/include/x86_64-linux-gnu/qt5/QtGui -fdiagnostics-color=always -Wall -Winvalid-pch -Wnon-virtual-dtor -Wextra -Wpedantic -Werror -std=c++17 -O3 -pedantic -Wno-unused-parameter -faligned-new -D_FILE_OFFSET_BITS=64 -Wno-psabi -DLIBAV_PRESENT=1 -DLIBDRM_PRESENT=1 -DQT_PRESENT=1 -fPIC -DQT_WIDGETS_LIB -DQT_GUI_LIB -DQT_CORE_LIB -pthread -DBOOST_ALL_NO_LIB -MD -MQ libcamera_app.so.1.2.2.p/preview_qt_preview.cpp.o -MF libcamera_app.so.1.2.2.p/preview_qt_preview.cpp.o.d -o libcamera_app.so.1.2.2.p/preview_qt_preview.cpp.o -c ../preview/qt_preview.cpp
In file included from /usr/include/x86_64-linux-gnu/qt5/QtCore/qlocale.h:43,
                 from /usr/include/x86_64-linux-gnu/qt5/QtGui/qguiapplication.h:47,
                 from /usr/include/x86_64-linux-gnu/qt5/QtWidgets/qapplication.h:52,
                 from /usr/include/x86_64-linux-gnu/qt5/QtWidgets/QApplication:1,
                 from ../preview/qt_preview.cpp:17:
/usr/include/x86_64-linux-gnu/qt5/QtCore/qvariant.h: In constructor ‘QVariant::QVariant(QVariant&&)’:
/usr/include/x86_64-linux-gnu/qt5/QtCore/qvariant.h:275:25: error: implicitly-declared ‘constexpr QVariant::Private& QVariant::Private::operator=(const QVariant::Private&)’ is deprecated [-Werror=deprecated-copy]
  275 |     { other.d = Private(); }
      |                         ^
/usr/include/x86_64-linux-gnu/qt5/QtCore/qvariant.h:401:16: note: because ‘QVariant::Private’ has user-provided ‘QVariant::Private::Private(const QVariant::Private&)’
  401 |         inline Private(const Private &other) Q_DECL_NOTHROW
      |                ^~~~~~~
cc1plus: all warnings being treated as errors
ninja: build stopped: subcommand failed.



import rclpy 
from rclpy.node import Node 
from sensor_msgs.msg import Image 
from geometry_msgs.msg import PointStamped
from cv_bridge import CvBridge 
import cv2 
import pyrealsense2 as rs
import numpy as np
 
class ImagePublisher(Node):
 
  def __init__(self):
 
  
    super().__init__('image_publisher')

    self.publisher_ = self.create_publisher(Image, '/camera/image_raw/compressed', 10) 
    self.bridge = CvBridge()
    self.center_sub = self.create_subscription(PointStamped , '/image/center_coordinates' , self.center_callback ,10)
    self.depth_pub = self.create_publisher(PointStamped , '/image/zDepth' , 10)

    self.pipeline =  rs.pipeline()
    config = rs.config()
    config.enable_stream(rs.stream.depth , 640 ,480 , rs.format.z16 , 30)
    config.enable_stream(rs.stream.color , 640 ,480 , rs.format.bgr8 , 30) # FPS = 30 

    self.pipeline.start(config)

  
    self.timer_period = 0.1  
    self.timer = self.create_timer(self.timer_period , self.timer_callback)
    self.x_center = None
    self.y_center = None 
    self.center_updated = False

  def timer_callback(self):
    frames = self.pipeline.wait_for_frames()  
    color_frame = frames.get_color_frame()
    depth_frame = frames.get_depth_frame()
    
    if not depth_frame or not color_frame:
      return

    color_image = np.asanyarray(color_frame.get_data()) 
    _ , compressed_image_data = cv2.imencode('.jpg' , color_image , [cv2.IMWRITE_JPEG_QUALITY , 20])
    compressed_image_data  = compressed_image_data.tobytes()
    msg = Image()
    msg.header.stamp = self.get_clock().now().to_msg()
    msg.data = compressed_image_data 
    msg.encoding = 'jpeg'
    self.publisher_ .publish(msg) 
#      self.timer_callback(self.x_center , self.y_center)

    if self.x_center is not None and self.y_center is not None:
      zDepth = depth_frame.get_distance(int(self.x_center),int(self.y_center))
      depth_msg = PointStamped()
      depth_msg.header.stamp = self.get_clock().now().to_msg()
      depth_msg.point.x = self.x_center
      depth_msg.point.y = self.y_center
      depth_msg.point.z = zDepth
      self.depth_pub.publish(depth_msg)
      self.get_logger().info(f"Depth is  : {zDepth}")
      self.center_updated = False
  
  def center_callback(self ,msg):
    
    self.x_center = msg.point.x
    self.y_center = msg.point.y
#    zDepth = depth_frame.get_distance(int(self.x_center),int(self.y_center))
#    self.center_callback(self.x_center ,self.y_center)
#    self.get_logger().info(f"Depth is  : {zDepth})")
#    self.get_logger().info('I heard: "%s"' % msg.zDepth)
    self.center_updated = True
#                  
    
   
def main(args=None):

  rclpy.init(args=args)
  

  image_publisher = ImagePublisher()

  rclpy.spin(image_publisher)
  
  rclpy.shutdown()
  
if __name__ == '__main__':
  main()










import rclpy
from rclpy.node import Node
from std_msgs.msg import String
import yaml

class RobotSpecPublisher(Node):
    def __init__(self):
        super().__init__('robot_spec_publisher')
        self.publisher_ = self.create_publisher(String, 'robot_specifications', 10)
        self.timer = self.create_timer(5.0, self.publish_robot_specs)

    def publish_robot_specs(self):
        # Load robot specifications from a YAML file
        with open('/path/to/your/config.yaml', 'r') as file:
            robot_specs = yaml.safe_load(file)
            specs_str = yaml.dump(robot_specs)
            self.publisher_.publish(String(data=specs_str))
            self.get_logger().info(f'Published robot specifications: {specs_str}')

def main(args=None):
    rclpy.init(args=args)
    robot_spec_publisher = RobotSpecPublisher()
    rclpy.spin(robot_spec_publisher)
    robot_spec_publisher.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()




import rclpy
from rclpy.node import Node
from std_msgs.msg import String
from geometry_msgs.msg import PoseStamped
import yaml

class TaskManager(Node):
    def __init__(self):
        super().__init__('task_manager')
        self.robot_specs = {}
        self.robot_navigators = {}  # Stores navigator instances or command publishers for each robot

        self.specs_subscription = self.create_subscription(
            String,
            'robot_specifications',
            self.handle_robot_specs,
            10)

    def handle_robot_specs(self, msg):
        specs = yaml.safe_load(msg.data)
        robot_name = specs["robot_name"]
        self.robot_specs[robot_name] = specs
        self.get_logger().info(f'Received specs from {robot_name}: {specs}')

        # Initialize navigator for the robot if not already done
        if robot_name not in self.robot_navigators:
            self.robot_navigators[robot_name] = self.create_robot_navigator(robot_name)
            self.get_logger().info(f"Navigator initialized for {robot_name}")

        self.evaluate_task()

    def create_robot_navigator(self, robot_name):
        # This function creates a publisher for the specific robot
        navigator_publisher = self.create_publisher(
            PoseStamped,
            f'/{robot_name}/goal_pose',
            10)
        return navigator_publisher

    def handle_robot_pose(self, pose_msg, robot_name):
        # Update robot's position in the stored specifications
        if robot_name in self.robot_specs:
            self.robot_specs[robot_name]['current_location'] = [
                pose_msg.pose.position.x,
                pose_msg.pose.position.y
            ]
            self.get_logger().info(f"Updated position for {robot_name}: {self.robot_specs[robot_name]['current_location']}")

    def evaluate_task(self):
        # Example task processing logic here
        # Decide which robot to assign the task to based on criteria
        chosen_robot_name = "robot1"  # Placeholder for chosen robot based on your criteria
        self.assign_task(chosen_robot_name, [2.0, 3.0])

    def assign_task(self, robot_name, task_location):
        if robot_name in self.robot_navigators:
            goal_pose = PoseStamped()
            goal_pose.header.frame_id = 'map'
            goal_pose.header.stamp = self.get_clock().now().to_msg()
            goal_pose.pose.position.x = task_location[0]
            goal_pose.pose.position.y = task_location[1]
            goal_pose.pose.orientation.w = 1.0  # Assuming the robot faces the task directly

            self.get_logger().info(
                f"Assigning task to {robot_name}. Sending to location {task_location}"
            )
            # Publish the goal pose to the specific robot's navigator
            self.robot_navigators[robot_name].publish(goal_pose)

def main(args=None):
    rclpy.init(args=args)
    task_manager = TaskManager()
    rclpy.spin(task_manager)
    task_manager.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()














cmake_minimum_required(VERSION 3.8)
project(navigation_turtlebot)

if(CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES "Clang")
  add_compile_options(-Wall -Wextra
# find dependencies
find_package(ament_cmake REQUIRED)
find_package(rclcpp REQUIRED)
find_package(nav_msgs REQUIRED)
# New Eidtions
find_package(ament_cmake_python REQUIRED)
find_package(rclpy REQUIRED)
#

# add_executable(pub_occupancy_grid src/pub_occupancy_grid.cpp)
# ament_target_dependencies(pub_occupancy_grid rclcpp nav_msgs)

# install(TARGETS
#   pub_occupancy_grid
#   DESTINATION lib/${PROJECT_NAME})

install( DIRECTORY launch/
         DESTINATION share/${PROJECT_NAME}/launch)
install( DIRECTORY config/
         DESTINATION share/${PROJECT_NAME}/config)


ament_python_install_package(${PROJECT_NAME})
# Python Executables into Lib

install(PROGRAMS scripts/single_goal_nav.py
        DESTINATION lib/${PROJECT_NAME})

        install(PROGRAMS scripts/multi_waypoints.py
        DESTINATION lib/${
        install(PROGRAMS scripts/robot_bringup.py
        DESTINATION lib/${PROJECT_NAME})

ament_package()
